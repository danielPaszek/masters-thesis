{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import io\n",
    "from Web.browse_edgar import *\n",
    "import csv\n",
    "import os\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.269679Z",
     "start_time": "2024-11-02T12:43:15.529128Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.sec.gov/ixviewer/ix.html?doc= (/Archives/edgar/data/320193/000162828017000717/a10-qq1201712312016.htm) is prefix for xlbr viewer :)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e877a097293dfc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying sec website. not actual filings\n",
    "\n",
    "https://www.macrotrends.net/stocks/charts/META/meta-platforms/financial-statements\n",
    "go to all financial statements\n",
    "interactive data :)\n",
    "\n",
    "10-q - to co szukamy kwartalne\n",
    "10-k - to co szukamy roczne"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1512c83eaa7fec2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def scrape_income_statement(driver):\n",
    "#     # TODO: https://stackoverflow.com/questions/8474031/case-insensitive-xpath-contains-possible\n",
    "#     table = open_income_statement(driver)\n",
    "#     lines = []\n",
    "#     for tr in table.find_elements(By.XPATH, \"./tr\"):\n",
    "#         line = []\n",
    "#         for th in tr.find_elements(By.XPATH, \"./th\") or []:\n",
    "#             text = th.text.strip()\n",
    "#             if text:\n",
    "#                 line.append(th.text)\n",
    "#         for td in tr.find_elements(By.XPATH, \"./td\") or []:\n",
    "#             text = td.text.strip()\n",
    "#             if text:\n",
    "#                 line.append(td.text)\n",
    "#         lines.append(line)\n",
    "#         \n",
    "#     title = lines.pop(0)\n",
    "#     try:\n",
    "#         date = pd.to_datetime(lines[0][0], format='%b. %d, %Y')\n",
    "#         dates = lines.pop(0)\n",
    "#     except:\n",
    "#         dates = title[1:]\n",
    "#         print('No date in second line')\n",
    "#     \n",
    "#     try:\n",
    "#         lines = list(filter(lambda x: len(x) > 1, lines))\n",
    "#         \n",
    "#         lines = np.array(lines)\n",
    "#         lines = np.char.replace(lines, '$', '')\n",
    "#         np.char.strip(lines)\n",
    "#         df = pd.DataFrame(lines, columns=['name', *dates])\n",
    "#     except:\n",
    "#         print(lines)\n",
    "#         return None\n",
    "#     return df.set_index('name')\n",
    "#     # return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.277655Z",
     "start_time": "2024-11-02T12:43:16.271688Z"
    }
   },
   "id": "ad01a6d6058fe8a5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parsed_income_statements = []\n",
    "def income_statement_to_df(driver):\n",
    "    table = open_income_statement(driver)\n",
    "    if table is None:\n",
    "        return None\n",
    "    f = io.StringIO('<table>' + table.get_attribute('innerHTML') + '</table>')\n",
    "    dfs = pd.read_html(f)\n",
    "    parsed_income_statements.append(dfs)\n",
    "    # 27.10\n",
    "    return dfs\n",
    "    # Rename doubled columns\n",
    "    df = dfs[0]\n",
    "    # df.iloc[:, 0] = df.iloc[:, 0] + df.groupby(df.iloc[:, 0]).cumcount().astype(str).replace('0', '')\n",
    "    return clean_from_html_weird_tables(df)\n",
    "\n",
    "    # if len(dfs) > 1:\n",
    "        # dodaj sprawdzenie który parsować\n",
    "    # return dfs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.288798Z",
     "start_time": "2024-11-02T12:43:16.280824Z"
    }
   },
   "id": "486ba1d97a2eba71",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# parsed_income_statements[3][0]\n",
    "# clean_from_html_weird_tables(parsed_income_statements[3][0])\n",
    "# df = parsed_income_statements[0][0].copy()\n",
    "# df.iloc[:, 0] = df.iloc[:, 0] + df.groupby(df.iloc[:, 0]).cumcount().astype(str).replace('0', '')\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.306052Z",
     "start_time": "2024-11-02T12:43:16.290809Z"
    }
   },
   "id": "4ea0b860cc03a7a5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import functools\n",
    "# parsed_income_statements[10][0]\n",
    "# df: pd.DataFrame = parsed_income_statements[12][0].copy()\n",
    "\n",
    "def clean_from_html_weird_tables(df):\n",
    "    df = df.loc[:, df.isnull().mean() < .9]\n",
    "# pusty nagłówek - ten dziwny nagłówek z dwóch wierszy\n",
    "    nan_df = df.isna().any(axis=1)\n",
    "    while nan_df[0]:\n",
    "        df = df.drop(0).reset_index(drop=True)\n",
    "        nan_df = df.isna().any(axis=1)\n",
    "\n",
    "    # 12 Months Ended jako wiersz\n",
    "    to_del = False\n",
    "    for v in df.iloc[0]:\n",
    "        if isinstance(v, str) and v.strip() == '12 Months Ended':\n",
    "            to_del = True\n",
    "    if to_del:  \n",
    "        df = df.drop(0)\n",
    "        \n",
    "    #     change to contains or something!\n",
    "    # UPDATE: idk co to\n",
    "    columns_to_drop = df[df == '[1]'].any(axis=0)\n",
    "    for i, v in enumerate(columns_to_drop):\n",
    "        if v:\n",
    "            df.drop(i, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.330583Z",
     "start_time": "2024-11-02T12:43:16.311062Z"
    }
   },
   "id": "f84065d66a7143a4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cleanup_df(df):\n",
    "    # remove multiIndex\n",
    "    df.to_csv('df.csv')\n",
    "    with open('df.csv', \"r+\") as f:\n",
    "        d = f.readlines()\n",
    "        f.seek(0)\n",
    "        for i, line in enumerate(d):\n",
    "            if i != 0:\n",
    "                f.write(line)\n",
    "        f.truncate()\n",
    "    df = pd.read_csv('df.csv')\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    # drop columns containing mostly NaN then drop NaN rows\n",
    "    df = df.loc[:, df.isnull().mean() < .8]\n",
    "    df = df.dropna()\n",
    "\n",
    "    \n",
    "    df = df.rename(columns={df.columns[0]: 'date'})\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df.map(lambda x: x.replace('$', '').replace(',', '').strip() if isinstance(x, str) and '$' in x else x)\n",
    "    df = df.transpose()\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.342706Z",
     "start_time": "2024-11-02T12:43:16.333700Z"
    }
   },
   "id": "723edb951daf3e27",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "debugBefore = []\n",
    "def use_search_page(driver, ticker):\n",
    "    buttons = driver.find_elements(By.XPATH, \"//a[contains(text(), 'Interactive Data')]\")\n",
    "    dfs = []\n",
    "    print(len(buttons))\n",
    "    debugBefore.clear()\n",
    "    if not os.path.isdir(f\"../data/raw/{ticker}\"):\n",
    "        os.mkdir(f\"../data/raw/{ticker}\")\n",
    "    for i in range(len(buttons)):\n",
    "        # try:\n",
    "            new_buttons = driver.find_elements(By.XPATH, \"//a[contains(text(), 'Interactive Data')]\")\n",
    "            new_buttons[i].click()\n",
    "            sleep(1)\n",
    "            ok = open_sections(driver)\n",
    "            if not ok:\n",
    "                print(\"No sections found - SKIPPING!!!!!!\")\n",
    "                file1 = open(\"errors.txt\", \"w\") \n",
    "                file1.write(ticker)\n",
    "                break\n",
    "            # df = income_statement_to_df(driver)\n",
    "            # 27.10\n",
    "            dfs = income_statement_to_df(driver)\n",
    "            if dfs is None:\n",
    "                print(\"skipping. Maybe 10-k/a?\")\n",
    "                driver.execute_script(\"window.history.go(-1)\")\n",
    "                continue\n",
    "            for dfNum, df in enumerate(dfs):\n",
    "                df.to_csv(f\"../data/raw/{ticker}/{i}-{dfNum}.csv\")\n",
    "            # END 27.10\n",
    "            # if df is None:\n",
    "            #     print(\"Skipping df\")\n",
    "            #     driver.execute_script(\"window.history.go(-1)\")\n",
    "            #     sleep(1)\n",
    "            #     continue\n",
    "            # \n",
    "            # debugBefore.append(df.copy())\n",
    "            # df = cleanup_df(df)   \n",
    "            # dfs.append(df)\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            print(\"done one\")\n",
    "            sleep(1)\n",
    "        # except:\n",
    "        #     continue\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.360764Z",
     "start_time": "2024-11-02T12:43:16.345715Z"
    }
   },
   "id": "90446325ce3b496",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def merge_dfs(dfs):\n",
    "    # merging 1 df is from bottom to top, meaning top values are more important than those with higher index\n",
    "    acc = {}\n",
    "    for i, df in enumerate(dfs):\n",
    "        for date, series in df.iterrows():\n",
    "            if date not in acc:\n",
    "                acc[date] = {}\n",
    "            for index, row in series.iloc[::-1].items():\n",
    "                acc[date][index] = row\n",
    "    return pd.DataFrame(acc), acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.381680Z",
     "start_time": "2024-11-02T12:43:16.363774Z"
    }
   },
   "id": "9a9d7a4a444c2d96",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df = debugBefore[0].copy()\n",
    "# cleanup_df(df)\n",
    "# # cleanup_df(test)\n",
    "# debugBefore[69]\n",
    "# TODO: Tesla has Total Revenue -> all sales, but has Revenue -> sales of 1 segment!\n",
    "# TODO: ATVI Cost of revenues -> false, Total costs and expenses true\n",
    "# TODO: CHECK AMG\n",
    "# acc['Dec. 31, 2021']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:43:16.394262Z",
     "start_time": "2024-11-02T12:43:16.385739Z"
    }
   },
   "id": "9e7bc1244d1080c0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=AIZ&type=10-K&dateb=&owner=exclude&count=100\n",
      "AIZ\n",
      "16\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=T&type=10-K&dateb=&owner=exclude&count=100\n",
      "T\n",
      "15\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=ADSK&type=10-K&dateb=&owner=exclude&count=100\n",
      "ADSK\n",
      "15\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=ADP&type=10-K&dateb=&owner=exclude&count=100\n",
      "ADP\n",
      "15\n",
      "No section found\n",
      "Fallback failed\n",
      "skipping. Maybe 10-k/a?\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m     driver\u001B[38;5;241m.\u001B[39mget(url)\n\u001B[0;32m     17\u001B[0m     sleep(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m     dfs \u001B[38;5;241m=\u001B[39m \u001B[43muse_search_page\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mticker\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# 27.10\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# debugDfs = [df.copy() for df in dfs]\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# resultDf, acc = merge_dfs(dfs)\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# resultDf.to_csv(ticker + \".csv\")\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSAVED TO CSV\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[7], line 12\u001B[0m, in \u001B[0;36muse_search_page\u001B[1;34m(driver, ticker)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(buttons)):\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# try:\u001B[39;00m\n\u001B[0;32m     11\u001B[0m         new_buttons \u001B[38;5;241m=\u001B[39m driver\u001B[38;5;241m.\u001B[39mfind_elements(By\u001B[38;5;241m.\u001B[39mXPATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m//a[contains(text(), \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInteractive Data\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m         \u001B[43mnew_buttons\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mclick()\n\u001B[0;32m     13\u001B[0m         sleep(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     14\u001B[0m         ok \u001B[38;5;241m=\u001B[39m open_sections(driver)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "search_url = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=$$$&type=10-K&dateb=&owner=exclude&count=100'\n",
    "# tickers = [\"AAPL\", 'MSFT', 'NVDA', 'GOOG', 'AMZN', 'META', 'AVGO', 'LLY', 'TSLA',]\n",
    "# tickers = [\"AAPL\", 'MSFT', 'NVDA', 'GOOG', 'AMZN', 'META', 'AVGO', 'LLY', 'TSLA', 'BRK-B',] \n",
    "# tickers = ['BRK-B']\n",
    "companies = {}\n",
    "# with open('sp500.csv', mode ='r')as file:\n",
    "with open('sp500-left2.csv', mode ='r')as file:\n",
    "  csvFile = csv.reader(file)\n",
    "  for line in csvFile:\n",
    "    ticker = line[0]\n",
    "# for ticker in tickers:\n",
    "    url = search_url.replace('$$$', ticker)\n",
    "    print(url)\n",
    "    print(ticker)\n",
    "    driver.get(url)\n",
    "    sleep(1)\n",
    "    dfs = use_search_page(driver, ticker)\n",
    "    # 27.10\n",
    "    # debugDfs = [df.copy() for df in dfs]\n",
    "    # resultDf, acc = merge_dfs(dfs)\n",
    "    # resultDf.to_csv(ticker + \".csv\")\n",
    "\n",
    "print(\"SAVED TO CSV\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:51:38.945925Z",
     "start_time": "2024-11-02T12:43:16.397454Z"
    }
   },
   "id": "3e09758760b97664",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
