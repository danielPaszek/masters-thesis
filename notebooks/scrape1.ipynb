{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import io\n",
    "from Web.browse_edgar import *\n",
    "import csv\n",
    "import os\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.845026Z",
     "start_time": "2024-10-27T16:34:05.839667Z"
    }
   },
   "id": "initial_id",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.sec.gov/ixviewer/ix.html?doc= (/Archives/edgar/data/320193/000162828017000717/a10-qq1201712312016.htm) is prefix for xlbr viewer :)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e877a097293dfc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying sec website. not actual filings\n",
    "\n",
    "https://www.macrotrends.net/stocks/charts/META/meta-platforms/financial-statements\n",
    "go to all financial statements\n",
    "interactive data :)\n",
    "\n",
    "10-q - to co szukamy kwartalne\n",
    "10-k - to co szukamy roczne"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1512c83eaa7fec2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scrape_income_statement(driver):\n",
    "    # TODO: https://stackoverflow.com/questions/8474031/case-insensitive-xpath-contains-possible\n",
    "    table = open_income_statement(driver)\n",
    "    lines = []\n",
    "    for tr in table.find_elements(By.XPATH, \"./tr\"):\n",
    "        line = []\n",
    "        for th in tr.find_elements(By.XPATH, \"./th\") or []:\n",
    "            text = th.text.strip()\n",
    "            if text:\n",
    "                line.append(th.text)\n",
    "        for td in tr.find_elements(By.XPATH, \"./td\") or []:\n",
    "            text = td.text.strip()\n",
    "            if text:\n",
    "                line.append(td.text)\n",
    "        lines.append(line)\n",
    "        \n",
    "    title = lines.pop(0)\n",
    "    try:\n",
    "        date = pd.to_datetime(lines[0][0], format='%b. %d, %Y')\n",
    "        dates = lines.pop(0)\n",
    "    except:\n",
    "        dates = title[1:]\n",
    "        print('No date in second line')\n",
    "    \n",
    "    try:\n",
    "        lines = list(filter(lambda x: len(x) > 1, lines))\n",
    "        \n",
    "        lines = np.array(lines)\n",
    "        lines = np.char.replace(lines, '$', '')\n",
    "        np.char.strip(lines)\n",
    "        df = pd.DataFrame(lines, columns=['name', *dates])\n",
    "    except:\n",
    "        print(lines)\n",
    "        return None\n",
    "    return df.set_index('name')\n",
    "    # return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.870239Z",
     "start_time": "2024-10-27T16:34:05.862395Z"
    }
   },
   "id": "ad01a6d6058fe8a5",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parsed_income_statements = []\n",
    "def income_statement_to_df(driver):\n",
    "    table = open_income_statement(driver)\n",
    "    if table is None:\n",
    "        return None\n",
    "    f = io.StringIO('<table>' + table.get_attribute('innerHTML') + '</table>')\n",
    "    dfs = pd.read_html(f)\n",
    "    parsed_income_statements.append(dfs)\n",
    "    # 27.10\n",
    "    return dfs\n",
    "    # Rename doubled columns\n",
    "    df = dfs[0]\n",
    "    # df.iloc[:, 0] = df.iloc[:, 0] + df.groupby(df.iloc[:, 0]).cumcount().astype(str).replace('0', '')\n",
    "    return clean_from_html_weird_tables(df)\n",
    "\n",
    "    # if len(dfs) > 1:\n",
    "        # dodaj sprawdzenie który parsować\n",
    "    # return dfs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.918867Z",
     "start_time": "2024-10-27T16:34:05.913327Z"
    }
   },
   "id": "486ba1d97a2eba71",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# parsed_income_statements[3][0]\n",
    "# clean_from_html_weird_tables(parsed_income_statements[3][0])\n",
    "# df = parsed_income_statements[0][0].copy()\n",
    "# df.iloc[:, 0] = df.iloc[:, 0] + df.groupby(df.iloc[:, 0]).cumcount().astype(str).replace('0', '')\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.928903Z",
     "start_time": "2024-10-27T16:34:05.920988Z"
    }
   },
   "id": "4ea0b860cc03a7a5",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import functools\n",
    "# parsed_income_statements[10][0]\n",
    "# df: pd.DataFrame = parsed_income_statements[12][0].copy()\n",
    "\n",
    "def clean_from_html_weird_tables(df):\n",
    "    df = df.loc[:, df.isnull().mean() < .9]\n",
    "# pusty nagłówek - ten dziwny nagłówek z dwóch wierszy\n",
    "    nan_df = df.isna().any(axis=1)\n",
    "    while nan_df[0]:\n",
    "        df = df.drop(0).reset_index(drop=True)\n",
    "        nan_df = df.isna().any(axis=1)\n",
    "\n",
    "    # 12 Months Ended jako wiersz\n",
    "    to_del = False\n",
    "    for v in df.iloc[0]:\n",
    "        if isinstance(v, str) and v.strip() == '12 Months Ended':\n",
    "            to_del = True\n",
    "    if to_del:  \n",
    "        df = df.drop(0)\n",
    "        \n",
    "    #     change to contains or something!\n",
    "    # UPDATE: idk co to\n",
    "    columns_to_drop = df[df == '[1]'].any(axis=0)\n",
    "    for i, v in enumerate(columns_to_drop):\n",
    "        if v:\n",
    "            df.drop(i, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.945296Z",
     "start_time": "2024-10-27T16:34:05.939734Z"
    }
   },
   "id": "f84065d66a7143a4",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cleanup_df(df):\n",
    "    # remove multiIndex\n",
    "    df.to_csv('df.csv')\n",
    "    with open('df.csv', \"r+\") as f:\n",
    "        d = f.readlines()\n",
    "        f.seek(0)\n",
    "        for i, line in enumerate(d):\n",
    "            if i != 0:\n",
    "                f.write(line)\n",
    "        f.truncate()\n",
    "    df = pd.read_csv('df.csv')\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    # drop columns containing mostly NaN then drop NaN rows\n",
    "    df = df.loc[:, df.isnull().mean() < .8]\n",
    "    df = df.dropna()\n",
    "\n",
    "    \n",
    "    df = df.rename(columns={df.columns[0]: 'date'})\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df.map(lambda x: x.replace('$', '').replace(',', '').strip() if isinstance(x, str) and '$' in x else x)\n",
    "    df = df.transpose()\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.957481Z",
     "start_time": "2024-10-27T16:34:05.946346Z"
    }
   },
   "id": "723edb951daf3e27",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "debugBefore = []\n",
    "def use_search_page(driver, ticker):\n",
    "    buttons = driver.find_elements(By.XPATH, \"//a[contains(text(), 'Interactive Data')]\")\n",
    "    dfs = []\n",
    "    print(len(buttons))\n",
    "    debugBefore.clear()\n",
    "    if not os.path.isdir(f\"../data/raw/{ticker}\"):\n",
    "        os.mkdir(f\"../data/raw/{ticker}\")\n",
    "    for i in range(len(buttons)):\n",
    "        # try:\n",
    "            new_buttons = driver.find_elements(By.XPATH, \"//a[contains(text(), 'Interactive Data')]\")\n",
    "            new_buttons[i].click()\n",
    "            sleep(1)\n",
    "            ok = open_sections(driver)\n",
    "            if not ok:\n",
    "                print(\"No sections found - SKIPPING!!!!!!\")\n",
    "                file1 = open(\"errors.txt\", \"w\") \n",
    "                file1.write(ticker)\n",
    "                break\n",
    "            # df = income_statement_to_df(driver)\n",
    "            # 27.10\n",
    "            dfs = income_statement_to_df(driver)\n",
    "            for dfNum, df in enumerate(dfs):\n",
    "                df.to_csv(f\"../data/raw/{ticker}/{i}-{dfNum}.csv\")\n",
    "            # END 27.10\n",
    "            # if df is None:\n",
    "            #     print(\"Skipping df\")\n",
    "            #     driver.execute_script(\"window.history.go(-1)\")\n",
    "            #     sleep(1)\n",
    "            #     continue\n",
    "            # \n",
    "            # debugBefore.append(df.copy())\n",
    "            # df = cleanup_df(df)   \n",
    "            # dfs.append(df)\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            print(\"done one\")\n",
    "            sleep(1)\n",
    "        # except:\n",
    "        #     continue\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.967061Z",
     "start_time": "2024-10-27T16:34:05.959719Z"
    }
   },
   "id": "90446325ce3b496",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def merge_dfs(dfs):\n",
    "    # merging 1 df is from bottom to top, meaning top values are more important than those with higher index\n",
    "    acc = {}\n",
    "    for i, df in enumerate(dfs):\n",
    "        for date, series in df.iterrows():\n",
    "            if date not in acc:\n",
    "                acc[date] = {}\n",
    "            for index, row in series.iloc[::-1].items():\n",
    "                acc[date][index] = row\n",
    "    return pd.DataFrame(acc), acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.986315Z",
     "start_time": "2024-10-27T16:34:05.978966Z"
    }
   },
   "id": "9a9d7a4a444c2d96",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df = debugBefore[0].copy()\n",
    "# cleanup_df(df)\n",
    "# # cleanup_df(test)\n",
    "# debugBefore[69]\n",
    "# TODO: Tesla has Total Revenue -> all sales, but has Revenue -> sales of 1 segment!\n",
    "# TODO: ATVI Cost of revenues -> false, Total costs and expenses true\n",
    "# TODO: CHECK AMG\n",
    "# acc['Dec. 31, 2021']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:34:05.997642Z",
     "start_time": "2024-10-27T16:34:05.987375Z"
    }
   },
   "id": "9e7bc1244d1080c0",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=A&type=10-K&dateb=&owner=exclude&count=100\n",
      "A\n",
      "15\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "done one\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=APD&type=10-K&dateb=&owner=exclude&count=100\n",
      "APD\n",
      "15\n",
      "SOMETHING WENT WRONG!!!!!!!!\n",
      "https://www.sec.gov/cgi-bin/viewer?action=view&cik=2969&accession_number=0000002969-23-000047&xbrl_type=v\n",
      "UWAGA!!!!!!!!!!!!!!!!!!!!\n",
      "No sections found - SKIPPING!!!!!!\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=AKAM&type=10-K&dateb=&owner=exclude&count=100\n",
      "AKAM\n",
      "15\n",
      "done one\n",
      "SOMETHING WENT WRONG!!!!!!!!\n",
      "https://www.sec.gov/cgi-bin/viewer?action=view&cik=1086222&accession_number=0001086222-23-000078&xbrl_type=v\n",
      "UWAGA!!!!!!!!!!!!!!!!!!!!\n",
      "No sections found - SKIPPING!!!!!!\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=ALK&type=10-K&dateb=&owner=exclude&count=100\n",
      "ALK\n",
      "14\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "No table found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m     driver\u001B[38;5;241m.\u001B[39mget(url)\n\u001B[0;32m     17\u001B[0m     sleep(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m     dfs \u001B[38;5;241m=\u001B[39m \u001B[43muse_search_page\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mticker\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# 27.10\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# debugDfs = [df.copy() for df in dfs]\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# resultDf, acc = merge_dfs(dfs)\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# resultDf.to_csv(ticker + \".csv\")\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSAVED TO CSV\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[17], line 22\u001B[0m, in \u001B[0;36muse_search_page\u001B[1;34m(driver, ticker)\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# df = income_statement_to_df(driver)\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# 27.10\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m dfs \u001B[38;5;241m=\u001B[39m \u001B[43mincome_statement_to_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dfNum, df \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dfs):\n\u001B[0;32m     24\u001B[0m     df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/raw/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mticker\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdfNum\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m, in \u001B[0;36mincome_statement_to_df\u001B[1;34m(driver)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mincome_statement_to_df\u001B[39m(driver):\n\u001B[1;32m----> 3\u001B[0m     table \u001B[38;5;241m=\u001B[39m \u001B[43mopen_income_statement\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m table \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mF:\\programowanie\\studia\\magisterka\\sec_scrapper2\\scientificProject\\Web\\browse_edgar.py:61\u001B[0m, in \u001B[0;36mopen_income_statement\u001B[1;34m(driver)\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m table:\n\u001B[1;32m---> 61\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo table found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m table\n",
      "\u001B[1;31mException\u001B[0m: No table found"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "search_url = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=$$$&type=10-K&dateb=&owner=exclude&count=100'\n",
    "# tickers = [\"AAPL\", 'MSFT', 'NVDA', 'GOOG', 'AMZN', 'META', 'AVGO', 'LLY', 'TSLA',]\n",
    "# tickers = [\"AAPL\", 'MSFT', 'NVDA', 'GOOG', 'AMZN', 'META', 'AVGO', 'LLY', 'TSLA', 'BRK-B',] \n",
    "# tickers = ['BRK-B']\n",
    "companies = {}\n",
    "# with open('sp500.csv', mode ='r')as file:\n",
    "with open('sp500-left2.csv', mode ='r')as file:\n",
    "  csvFile = csv.reader(file)\n",
    "  for line in csvFile:\n",
    "    ticker = line[0]\n",
    "# for ticker in tickers:\n",
    "    url = search_url.replace('$$$', ticker)\n",
    "    print(url)\n",
    "    print(ticker)\n",
    "    driver.get(url)\n",
    "    sleep(1)\n",
    "    dfs = use_search_page(driver, ticker)\n",
    "    # 27.10\n",
    "    # debugDfs = [df.copy() for df in dfs]\n",
    "    # resultDf, acc = merge_dfs(dfs)\n",
    "    # resultDf.to_csv(ticker + \".csv\")\n",
    "\n",
    "print(\"SAVED TO CSV\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T16:39:13.590112Z",
     "start_time": "2024-10-27T16:34:06.006132Z"
    }
   },
   "id": "3e09758760b97664",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
